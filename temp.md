现在的whisperx识别了语音之后，会产出srt文件，我的想法是，调用gemini cli，根据srt文件，从中提取所有speaker的语音样本，然后跟我确认。我之前的做法是在gemini cli中创建了一个toml命令。内容如下：
description = "从播客音频中自动提取高质量语音样本"
prompt = '''

从播客音频中自动提取高质量语音样本
1. 任务概述
您是一名专业的播客剪辑师。请严格遵循以下所有步骤，为播客音频中的每一位发言人提取一个高质量的6秒～12秒的音频样本，用于发言人的语音克隆。

2. 【关键】执行模式：计划与确认
在开始任何文件操作之前，您必须遵循以下模式：

生成Todolist: 根据下文“任务分解”中的步骤，生成一个清晰的、分步的Todolist，并首先将其展示给用户。
逐步执行与确认: 严格按照Todolist的顺序执行。每完成一个项目，都必须明确地确认该步骤已完成，然后再进行下一步。
3. 任务分解 (用于Todolist)
步骤 1: 动态分析元数据
1a. 分析发言人数量: 自动分析提供的文字稿文件 (.pdf)，确定唯一的发言人总数。
1b. 动态确定正片开始时间: 分析文字稿，识别其中的广告内容、前置引入和介绍的内容，找到播客正片内容开始的准确时间（一般至少会在音频开始后的三分钟以后），并确定其时间戳。
步骤 2: 分析发言人的标志性语音所处时间
2a. 分析文本: 根据文字稿文件，分析每位发言人标志性语音的大致时间，通常会在音频开始3分钟后到结束前10分钟之间
步骤 3: 逐一提取音频样本
3a. 为每位发言人循环执行:
定位与分析: 使用ffmpeg和silencedetect过滤器，结合文字稿，为当前发言人找到一个时长在6秒以上，但不超过11秒、被清晰静音包围的独立句子。这个句子应该尽可能说完整，而不是中间被截断
精确剪辑: 无损提取发言人音频到临时文件
添加静音: 对临时文件的尾部添加时长为1秒钟的静音生成最终的speakerN.MP3文件
步骤 4: 对音频进行检查和反思
4a. 列出所有产物: 显示当前目录下所有生成的speakerN.MP3文件。
4b. 检查和反思: 用你自带的工具，逐一读取每个生成的音频文件，对生成的音频文件质量进行检查和反思，并输出反思和优化建议。
检查重点：
时长是否在6s～12s之间
音频是否只有单一发言人的声音，特别需要检查音频的开头和结尾有没有杂音或者其他发言人的声音
音频的结尾最后一秒是否为静音
4c. 对音频进行优化: 根据反思报告，对生成的音频文件进行优化，必要时重新选择合适的发言人片段进行重新剪辑
步骤 5: 最终验证与交付
5a. 列出所有产物: 显示当前目录下所有生成的speakerN.MP3文件。
5b. 回听确认: 用你自带的工具，逐一读取每个生成的音频文件，对生成的音频文件质量进行最终检查和反思
5c. 删除临时文件: 删除临时文件和中间文件，只保留最终优化过的speakerN.MP3文件
5c. 任务完成: 宣布整个任务已根据模板要求全部完成。
4. 开始执行
如果您已理解以上所有指令，并且用户已提供了所需的音频和文字稿文件，请立即开始生成并执行您的Todolist。
'''

但是这个要手动来完成，然后有时候会出现读取不到所有的speaker等情况。我想你帮我分析一下这个需求，找出更好的和更稳定并且能跟我们目前的语音合成、语音转文本的流程相结合的方式。请你先深度思考和规划，先不要修改代码
